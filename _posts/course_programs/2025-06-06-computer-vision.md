---
layout: post
title: Visión por computadora aplicada a la biodiversidad
date:   2025-06-06
categories: [Courses]
permalink: /courses/vision-program
lang-ref: vision-program
---

## Descripción
<div style="text-align: justify">
<p>La visión por computadora es un campo de la Inteligencia Artificial que tiene por objetivo enseñar a las máquinas a "ver" y a interpretar las imágenes en la forma en que lo hacemos los humanos. Esto ha llevado a importantes desarrollos tecnológicos autónomos como la robótica y los vehículos autónomos. De esta forma, la Conservación de la Biodiversidad también se ve beneficiada por los avances en la visión por computadora, ya que permite analizar e interpretar datos biológicos complejos extraídos de imágenes de diferentes fuentes con mayor eficiencia y precisión. Aprender sobre visión artificial proporciona a estos profesionales herramientas claves para avanzar en la investigación, así como mejorar la comprensión y conocimiento sobre las especies y las áreas de conservación de biodiversidad.</p>
<p>Este curso se enfoca en la compresión de los conceptos básicos de visión por computadora desde la perspectiva del uso de cámaras trampa ya que esta es una de las aplicaciones más importantes de la visión por computadora aplicada a la conservación de la biodiversidad. Se incluyen tareas comunes involucradas en estos proyectos como son el preprocesamiento, extracción de características, segmentación, y detección y reconocimiento de objetos para el posterior análisis e interpretación de los datos obtenidos a partir de las imágenes. Este curso no abarca tareas como el diseño del sistemas de cámaras trampa, la adquisición de imágenes o aspectos administrativos de dichos sistemas.</p>
<p>Este curso surge en respuesta a las necesidades de capacitación en diferentes áreas de la Ciencia de Datos diagnosticadas por la Red de Ciencia de datos para la Conservación de la Biodiversidad Mesoamericana (Redbioma). Está dirigido a profesionales que se desempeñan en actividades relacionadas con la Conservación de la Biodiversidad, por lo que se encuentra enfocado en la solución de problemas y el desarrollo de conocimientos y habilidades en procesamiento y análisis de imágenes mediante el uso de herramientas, programación básica basada en bibliotecas de manejo de imágenes en Python y el uso de modelos de Aprendizaje Automático preentrenados aplicados a colecciones de imágenes disponibles en repositorios públicos.</p>
</div>
<br>

<div>
<b>Horario y fecha de inicio</b>
<ul>
    <li>Inicia el martes 24 de junio y finaliza el 12 de agosto de 2025.</li>
    <li>Se impartirá todos los martes de 18:00 a 20:00 horas (GMT-6) durante 8 semanas.</li>
</ul>
</div>
<br>

<div>
<b>Tipo de curso</b>
<br>
<ul>
    <li>Modalidad: Virtual.</li>
    <li>Teórico/Práctico: Para completar el programa, es necesario tener una asistencia efectiva de más del 75% de las clases sincrónicas virtuales, y sus evaluaciones con un promedio mayor o igual a 70.</li>
    <li>Costo: Gratuito.</li>
</ul>
</div>
<br>

<div>
<b>Requisitos</b>
<ul>
  <li>Tener disponibilidad de al menos 16 horas durante todo el programa para asistir a ocho sesiones sincrónicas virtuales de clases. (2hrs / clase)</li>
  <li>Tener disponibilidad de al menos 24 horas durante todo el programa para realizar tareas cortas, ver videos ilustrativos, lecturas adicionales, laboratorios prácticos del curso y un proyecto final. (3hrs / semana)</li>
  <li>Conocimientos básicos del lenguaje de programación Python, bibliotecas Numpy y Pandas para el manejo de datos y GeoPandas para el procesamiento de datos geoespaciales. También es necesario el conocimiento básico de modelos de aprendizaje automático. De preferencia haber aprobado el curso de <i>Introducción a Python para Ciencia de Datos</i>, y opcionalmente el curso de <i>Aprendizaje Automático</i> que se ofrecen como parte de este Programa de Capacitación.</li>
  <li>Llenar el formulario para <a href="https://forms.gle/gq98uQN32xz9uBx87">Participar en las actividades de la Redbioma</a> (anteriormente circulado, por favor llenarlo una sola vez).</li>
</ul>
</div>
<br>

## Formulario de inscripción
Enlace: [Inscripciones Visión por Computadora aplicada a la Biodiversidad](https://forms.gle/tCovPqgZxrN5h3qR9)

<br>

## Objetivos

#### General
<div style="text-align: justify">
<p>El desarrollo de habilidades de procesamiento y análisis de imágenes comúnmente asociadas a los sistemas de cámaras trampa, utilizando herramientas comunes, programación en Python y técnicas de aprendizaje automático.</p>
</div>
<br>

#### Específicos
<div style="text-align: justify"><ul>
    <li>Construir una comprensión de los conceptos generales de visión por computadora asociados al procesamiento y análisis de imágenes así como aquellos específicos a diferentes áreas de la Conservación de la Biodiversidad.</li>
    <li>Diferenciar entre tareas comunes de procesamiento y análisis de imágenes.</li>
    <li>Utilizar herramientas populares de acceso libre para el procesamiento y análisis de imágenes de biodiversidad.</li>
    <li>Implementar rutinas básicas basadas en bibliotecas de Python orientadas a la manipulación de imágenes obtenidas de sistemas de cámaras trampa.</li>
    <li>Conocer y aplicar modelos básicos de aprendizaje automático para el procesamiento y análisis de imágenes de cámaras trampa.</li>
</ul></div>
<br>

## Metodología del curso

<div style="text-align: justify">
<p>La metodología del curso estará basada en aprendizaje activo y colaborativo, por medio de resolución de problemas planteados en los laboratorios, trabajo de investigación y aula invertida, entre otras técnicas. Se propone guiar a las personas estudiantes para que estas fortalezcan su capacidad de investigar, utilizar colecciones de datos públicas, analizar críticamente artículos científicos y aplicar nuevos conceptos teniendo como base el conocimiento adquirido previamente y los contenidos del curso.</p>
<p>El programa del curso es teórico/práctico donde los participantes pondrán en práctica los conocimientos teóricos mediante casos de estudios, discusiones grupales, laboratorios y un proyecto final.</p>
<b>Importante:</b>
<ul>
    <li>Todas las sesiones sincrónicas serán grabadas y publicadas en el sitio web del proyecto.</li>
    <li>Los proyectos finales de investigación serán publicados en el sitio web del proyecto.</li>
</ul>
</div>
<br>

## Contenidos del programa
<div style="text-align: justify">
  <ol>
    <b><li>Fundamentos de visión por computadora</li></b>
    <ol type="i">
        <li>Imágenes, conceptos básicos.</li>
        <li>Tareas básicas relacionadas con visión por computadora.</li>
        <li>Modelos populares de Visión por Computadora basadas en Aprendizaje Automático y Aprendizaje Profundo.</li>
        <li>Herramientas básicas y bibliotecas de uso común en Python.</li>
    </ol>
    <b><li>Introducción al procesamiento de imágenes</li></b>
    <ol type="i">
        <li>Descripción de tareas comunes de procesamiento de imágenes.</li>
          <ol type="i">
            <li>Preprocesamiento.</li>
            <li>Mejoramiento.</li>
            <li>Segmentación.</li>
            <li>Extracción de características.</li>
          </ol>
        <li>Herramientas específicas de procesamiento de imágenes de biodiversidad.</li>
        <li>Implementación de tareas comunes de procesamiento de imágenes en Python.</li>
        <li>Aplicación de modelos preentrenados basados en técnicas de aprendizaje supervisado.</li>
    </ol>
    <b><li>Introducción al análisis de imágenes</li></b>
    <ol type="i">
        <li>Descripción de tareas comunes de análisis de imágenes.</li>
          <ol type="i">
            <li>Anotación.</li>
            <li>Clasificación de imágenes.</li>
            <li>Detección de movimiento.</li>
            <li>Detección de anomalías.</li>
          </ol>
        <li>Herramientas específicas de análisis de imágenes de biodiversidad.</li>
        <li>Implementación de tareas comunes de análisis de imágenes en Python.</li>
        <li>Aplicación de modelos preentrenados basados en técnicas de aprendizaje supervisado.</li>
    </ol>
    <b><li>Sistemas de cámaras trampa</li></b>
    <ol type="i">
        <li>Definiciones y conceptos básicos.</li>
        <li>Estándares de datos: CamTrap DP.</li>
        <li>Procesamiento de imágenes de cámaras trampa.</li>
          <ol type="i">
            <li>Organización.</li>
            <li>Limpieza: Duplicados y falsos triggers.</li>
            <li>Etiquetado.</li>
            <li>Herramientas y modelos basados en aprendizaje automático.</li>
          </ol>
        <li>Análisis de imágenes de cámaras trampa.</li>
          <ol type="i">
            <li>Reconocimiento de especies.</li>
            <li>Modelos de ocupación de especies.</li>
            <li>Patrones de actividad.</li>
            <li>Herramientas y modelos basados en aprendizaje automático.</li>
          </ol>
    </ol>
    <b><li>Reflexiones finales</li></b>
    <ol type="i">
        <li>Retos y riesgos del uso de imágenes en la conservación de la biodiversidad.</li>
        <li>Oportunidades de uso de cámaras trampa en el contexto profesional de los participantes.</li>
    </ol>
</ol>
</div>
<br>


## Evaluación
<div style="text-align: justify">
<p>Las personas estudiantes llevarán a cabo tareas cortas, laboratorios y un proyecto final. Los rubros de las evaluaciones serán los siguientes:</p>
</div>
<br>

<table style="width:30%">
  <tr>
    <th>Rubro</th>
    <th>Valor (%)</th>
  </tr>
  <tr>
    <td>Tareas cortas</td>
    <td>30</td>
  </tr>
  <tr>
    <td>Laboratorios</td>
    <td>30</td>
  </tr>
  <tr>
    <td>Participación en clase</td>
    <td>10</td>
  </tr>
  <tr>
    <td>Proyecto final</td>
    <td>30</td>
  </tr>
  <tr>
    <td>Total</td>
    <td>100</td>
  </tr>
</table>

<div style="text-align: justify">
<p>Las tareas cortas permitirán el reforzamiento de los conocimientos y habilidades adquiridas durante las sesiones sincrónicas y permitirán a los participantes explorar temas complementarios al curso. Los laboratorios serán realizados durante las sesiones sincrónicas utilizando variados recursos y entornos. Las colecciones de imágenes estarán disponibles previo el inicio de cada sesión. La participación en clase incluye la participación oral del estudiante así como realizar satisfactoriamente las actividades propuestas para la sesión. El proyecto final consiste en la elaboración de un póster de conferencia que presente los resultados de la implementación de tareas de procesamiento y análisis de imágenes para un caso de uso común en un sistema de cámaras trampa.</p>
<p>Cada evaluación tendrá una fecha de entrega previamente establecida. La hora límite de las entregas será a las 23:45 GMT-6. No se reciben entregas tardías. El medio de entrega será la plataforma Google Classroom.</p>
</div>
<br>

## Cronograma de clases

<table style="width:60%">
  <tr>
    <th>Clase</th>
    <th>Semana</th>
  </tr>
  <tr>
    <td>Fundamentos de visión por computadora</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Introducción al procesamiento de imágenes</td>
    <td>1-2</td>
  </tr>
  <tr>
    <td>Introducción al análisis de imágenes</td>
    <td>3-4</td>
  </tr>
  <tr>
    <td>Procesamiento y análisis de imágenes de sistemas de cámaras trampa</td>
    <td>5-8</td>
  </tr>
  <tr>
    <td>Reflexiones finales y presentación de posters</td>
    <td>8</td>
  </tr>
</table>
<br>

## Recursos

- Bibliotecas de Python: Pillow, OpenCV, scikit-image, Tensorflow, Keras.
- Plataformas basadas en Inteligencia Artificial: Wildlife Insights (WI), Machine Learning for Wildlife Image Classification (MLWIC2), MegaDetector (MD), y Conservation AI.
- Herramientas de procesamiento y análisis de imágenes: Timelapse, Camelot.
- Colecciones de imágenes públicas obtenidas de repositorios como GBIF y CalTech.
- GBIF Webinars.

<br>

## Referencias

1. Duggan, M. T., Groleau, M. F., Shealy, E. P., Self, L. S., Utter, T. E., Waller, M. M., Hall, B. C., Stone, C. G., Anderson, L. L., & Mousseau, T. A. (2021). An approach to rapid processing of camera trap images with minimal human input. *Ecology and Evolution, 11*(17), 12051–12063. [Enlace externo](https://doi.org/10.1002/ece3.7970)

2. Egloff W, Agosti D, Kishor P, Patterson D, Miller J (2017). Copyright and the Use of Images as Biodiversity Data. *Research Ideas and Outcomes 3*: e12502. [Enlace externo](https://doi.org/10.3897/rio.3.e12502)

3. Fennell, M., Beirne, C., & Burton, A. C. (2022). Use of object detection in camera trap image identification: Assessing a method to rapidly and accurately classify human and animal detections for research and application in recreation ecology. *Global Ecology and Conservation, 35*, e02104. [Enlace externo](https://doi.org/10.1016/j.gecco.2022.e02104)

4. Fergus, P., Chalmers, C., Longmore, S., & Wich, S. (2024). Harnessing Artificial Intelligence for Wildlife Conservation. *Conservation, 4*(4), 685–702. [Enlace externo](https://doi.org/10.3390/conservation4040041)

5. Greenberg, S. (n.d.). *Automated Image Recognition for Wildlife Camera Traps: Making it Work for You 1*. Retrieved June 4, 2025, from [Enlace externo](https://wildcams.ca/site/assets/files/1389/2020-08-greenberg-imagerecognitioncameratraps_updated.pdf)

6. Hilton, M. L., Yamane, M. T., & Knezevich, L. M. (2022). *An Image Processing Pipeline for Camera Trap Time-Lapse Recordings*. ArXiv.org. [Enlace externo](https://arxiv.org/abs/2206.05159)

7. Leorna, S., & Brinkman, T. (2022). Human vs. machine: Detecting wildlife in camera trap images. *Ecological Informatics, 72*, 101876. [Enlace externo](https://doi.org/10.1016/j.ecoinf.2022.101876)

8. Pantazis, O., Bevan, P., Pringle, H., Ferreira, G. B., Ingram, D. J., Madsen, E., Thomas, L., Raj, T. D., Silwal, T., Rayamajhi, S., Brostow, G., Aodha, M., & Jones, K. E. (2024). *Deep learning-based ecological analysis of camera trap images is impacted by training data quality and size*. ArXiv.org. [Enlace externo](https://arxiv.org/abs/2408.14348)

9. Vélez, J., McShea, W., Shamon, H., Castiblanco-Camacho, P. J., Tabak, M. A., Chalmers, C., Fergus, P., & Fieberg, J. (2022). An evaluation of platforms for processing camera-trap data using artificial intelligence. *Methods in Ecology and Evolution, 14*(2), 459–477. [Enlace externo](https://doi.org/10.1111/2041-210x.1404)

<br>

## Contactos

<table style="width:40%">
  <tr>
    <th>Persona facilitadora</th>
    <th>Correo electrónico</th>
  </tr>
  <tr>
    <td>Instructor: Emilia Zeledón</td>
    <td><a href="mailto:emilia.zeledon@gmail.com">emilia.zeledon@gmail.com</a></td>
  </tr>
  <tr>
    <td>María Auxiliadora Mora</td>
    <td><a href="mailto:maria.mora@itcr.ac.cr">maria.mora@itcr.ac.cr</a></td>
  </tr>
</table>
